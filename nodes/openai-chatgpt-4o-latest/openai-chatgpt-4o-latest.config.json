{
  "display_name": "OpenAI: ChatGPT-4o",
  "description": "OpenAI ChatGPT 4o is continually updated by OpenAI to point to the current version of GPT-4o used by ChatGPT. It therefore differs slightly from the API version of [GPT-4o](/models/openai/gpt-4o) in that it has additional RLHF. It is intended for research and evaluation.\n\nOpenAI notes that this model is not suited for production use-cases as it may be removed or redirected to another model in the future.",
  "category": "llm",
  "provider": "openai",
  "accepts_plugins": false,
  "model_id": "openai/chatgpt-4o-latest",
  "context_length": 128000,
  "supported_parameters": [
    "frequency_penalty",
    "logit_bias",
    "logprobs",
    "max_tokens",
    "presence_penalty",
    "response_format",
    "seed",
    "stop",
    "structured_outputs",
    "temperature",
    "top_logprobs",
    "top_p"
  ],
  "inputs": [
    {
      "name": "prompt",
      "display_name": "Prompt",
      "type": "string",
      "description": "Text prompt for completion",
      "required": true
    },
    {
      "name": "temperature",
      "display_name": "Temperature",
      "type": "number",
      "description": "Controls randomness (0-2)",
      "default": null
    },
    {
      "name": "max_tokens",
      "display_name": "Max Tokens",
      "type": "number",
      "description": "Maximum tokens to generate",
      "default": null
    },
    {
      "name": "top_p",
      "display_name": "Top P",
      "type": "number",
      "description": "Controls diversity via nucleus sampling",
      "default": null
    },
    {
      "name": "frequency_penalty",
      "display_name": "Frequency Penalty",
      "type": "number",
      "description": "Reduces repetition (-2 to 2)",
      "default": null
    },
    {
      "name": "presence_penalty",
      "display_name": "Presence Penalty",
      "type": "number",
      "description": "Encourages new topics (-2 to 2)",
      "default": null
    },
    {
      "name": "response_format",
      "display_name": "Response Format",
      "type": "string or object",
      "description": "Output format specification",
      "default": null
    },
    {
      "name": "seed",
      "display_name": "Seed",
      "type": "number",
      "description": "Deterministic outputs",
      "default": null
    },
    {
      "name": "stop",
      "display_name": "Stop",
      "type": "string or array",
      "description": "Custom stop sequences",
      "default": null
    },
    {
      "name": "structured_outputs",
      "display_name": "Structured Outputs",
      "type": "string or object",
      "description": "JSON schema enforcement",
      "default": null
    }
  ],
  "outputs": [
    {
      "name": "content",
      "display_name": "Content",
      "can_stream": true,
      "type": "string",
      "description": "The generated completion text"
    },
    {
      "name": "finish_reason",
      "display_name": "Finish Reason",
      "type": "string",
      "description": "Why the completion finished"
    },
    {
      "name": "usage",
      "display_name": "Token Usage",
      "type": "object",
      "description": "Token usage statistics"
    },
    {
      "name": "cost_total",
      "display_name": "Total Cost",
      "type": "number",
      "description": "Total cost for processing this request (USD)"
    },
    {
      "name": "cost_itemized",
      "display_name": "Itemized Cost",
      "type": "array",
      "description": "Detailed breakdown of costs"
    },
    {
      "name": "logprobs",
      "display_name": "Log Probabilities",
      "type": "object",
      "description": "Token probabilities and logprobs from the model"
    }
  ],
  "pricing": {
    "reference": "https://openrouter.ai/models",
    "items": [
      {
        "key": "input_cost_per_million",
        "label": "Input Tokens (per 1M)",
        "cost": 5,
        "currency": "USD"
      },
      {
        "key": "output_cost_per_million",
        "label": "Output Tokens (per 1M)",
        "cost": 15,
        "currency": "USD"
      }
    ]
  }
}