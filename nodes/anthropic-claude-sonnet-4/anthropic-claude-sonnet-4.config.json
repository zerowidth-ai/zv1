{
  "display_name": "Anthropic: Claude Sonnet 4",
  "description": "Claude Sonnet 4 significantly enhances the capabilities of its predecessor, Sonnet 3.7, excelling in both coding and reasoning tasks with improved precision and controllability. Achieving state-of-the-art performance on SWE-bench (72.7%), Sonnet 4 balances capability and computational efficiency, making it suitable for a broad range of applications from routine coding tasks to complex software development projects. Key enhancements include improved autonomous codebase navigation, reduced error rates in agent-driven workflows, and increased reliability in following intricate instructions. Sonnet 4 is optimized for practical everyday use, providing advanced reasoning capabilities while maintaining efficiency and responsiveness in diverse internal and external scenarios.\n\nRead more at the [blog post here](https://www.anthropic.com/news/claude-4)",
  "category": "llm",
  "provider": "anthropic",
  "accepts_plugins": true,
  "model_id": "anthropic/claude-sonnet-4",
  "context_length": 200000,
  "supported_parameters": [
    "include_reasoning",
    "max_tokens",
    "reasoning",
    "stop",
    "temperature",
    "tool_choice",
    "tools",
    "top_k",
    "top_p"
  ],
  "inputs": [
    {
      "name": "system_prompt",
      "display_name": "System Prompt",
      "type": "string or message",
      "description": "System prompt for the model",
      "default": null
    },
    {
      "name": "messages",
      "display_name": "Messages",
      "type": "array of messages or message or string",
      "description": "Array of chat messages",
      "required": true
    },
    {
      "name": "tools",
      "display_name": "Tools",
      "type": "tool",
      "description": "Array of tools to use",
      "default": null,
      "allow_multiple": true
    },
    {
      "name": "temperature",
      "display_name": "Temperature",
      "type": "number",
      "description": "Controls randomness (0-2)",
      "default": null
    },
    {
      "name": "max_tokens",
      "display_name": "Max Tokens",
      "type": "number",
      "description": "Maximum tokens to generate",
      "default": null
    },
    {
      "name": "top_p",
      "display_name": "Top P",
      "type": "number",
      "description": "Controls diversity via nucleus sampling",
      "default": null
    },
    {
      "name": "include_reasoning",
      "display_name": "Include Reasoning",
      "type": "boolean",
      "description": "Include reasoning in response",
      "default": null
    },
    {
      "name": "reasoning",
      "display_name": "Reasoning",
      "type": "boolean",
      "description": "Internal reasoning mode",
      "default": null
    },
    {
      "name": "stop",
      "display_name": "Stop",
      "type": "string or array",
      "description": "Custom stop sequences",
      "default": null
    },
    {
      "name": "tool_choice",
      "display_name": "Tool Choice",
      "type": "string",
      "description": "Tool selection control",
      "default": null
    }
  ],
  "outputs": [
    {
      "name": "content",
      "display_name": "Content",
      "can_stream": true,
      "type": "string",
      "description": "The content portion of the generated response message."
    },
    {
      "name": "message",
      "display_name": "Message",
      "type": "message",
      "can_stream": true,
      "description": "The full generated response message."
    },
    {
      "name": "role",
      "display_name": "Role",
      "can_stream": true,
      "type": "string",
      "description": "Role of the response (usually 'assistant')"
    },
    {
      "name": "tool_calls",
      "display_name": "Tool Calls",
      "type": "array of tools",
      "description": "Tool calls made by the model"
    },
    {
      "name": "finish_reason",
      "display_name": "Finish Reason",
      "type": "string",
      "description": "Why the completion finished"
    },
    {
      "name": "usage",
      "display_name": "Token Usage",
      "type": "object",
      "description": "Token usage statistics"
    },
    {
      "name": "cost_total",
      "display_name": "Total Cost",
      "type": "number",
      "description": "Total cost for processing this request (USD)"
    },
    {
      "name": "cost_itemized",
      "display_name": "Itemized Cost",
      "type": "array",
      "description": "Detailed breakdown of costs"
    },
    {
      "name": "reasoning",
      "display_name": "Reasoning",
      "type": "string",
      "description": "The detailed reasoning chain from the model"
    },
    {
      "name": "refusal",
      "display_name": "Refusal",
      "type": "string",
      "description": "Model refusal response (if any)"
    }
  ],
  "pricing": {
    "reference": "https://openrouter.ai/models",
    "items": [
      {
        "key": "input_cost_per_million",
        "label": "Input Tokens (per 1M)",
        "cost": 3,
        "currency": "USD"
      },
      {
        "key": "output_cost_per_million",
        "label": "Output Tokens (per 1M)",
        "cost": 15,
        "currency": "USD"
      }
    ]
  }
}