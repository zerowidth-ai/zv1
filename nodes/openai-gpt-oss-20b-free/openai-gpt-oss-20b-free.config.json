{
  "display_name": "OpenAI: gpt-oss-20b (free)",
  "description": "gpt-oss-20b is an open-weight 21B parameter model released by OpenAI under the Apache 2.0 license. It uses a Mixture-of-Experts (MoE) architecture with 3.6B active parameters per forward pass, optimized for lower-latency inference and deployability on consumer or single-GPU hardware. The model is trained in OpenAIâ€™s Harmony response format and supports reasoning level configuration, fine-tuning, and agentic capabilities including function calling, tool use, and structured outputs.",
  "category": "llm",
  "provider": "openai",
  "accepts_plugins": false,
  "model_id": "openai/gpt-oss-20b:free",
  "context_length": 131072,
  "supported_parameters": [
    "include_reasoning",
    "max_tokens",
    "reasoning",
    "response_format",
    "structured_outputs",
    "temperature",
    "top_p"
  ],
  "inputs": [
    {
      "name": "prompt",
      "display_name": "Prompt",
      "type": "string",
      "description": "Text prompt for completion",
      "required": true
    },
    {
      "name": "temperature",
      "display_name": "Temperature",
      "type": "number",
      "description": "Controls randomness (0-2)",
      "default": null
    },
    {
      "name": "max_tokens",
      "display_name": "Max Tokens",
      "type": "number",
      "description": "Maximum tokens to generate",
      "default": null
    },
    {
      "name": "top_p",
      "display_name": "Top P",
      "type": "number",
      "description": "Controls diversity via nucleus sampling",
      "default": null
    },
    {
      "name": "include_reasoning",
      "display_name": "Include Reasoning",
      "type": "boolean",
      "description": "Include reasoning in response",
      "default": null
    },
    {
      "name": "reasoning",
      "display_name": "Reasoning",
      "type": "boolean",
      "description": "Internal reasoning mode",
      "default": null
    },
    {
      "name": "response_format",
      "display_name": "Response Format",
      "type": "string or object",
      "description": "Output format specification",
      "default": null
    },
    {
      "name": "structured_outputs",
      "display_name": "Structured Outputs",
      "type": "string or object",
      "description": "JSON schema enforcement",
      "default": null
    }
  ],
  "outputs": [
    {
      "name": "content",
      "display_name": "Content",
      "can_stream": true,
      "type": "string",
      "description": "The generated completion text"
    },
    {
      "name": "finish_reason",
      "display_name": "Finish Reason",
      "type": "string",
      "description": "Why the completion finished"
    },
    {
      "name": "usage",
      "display_name": "Token Usage",
      "type": "object",
      "description": "Token usage statistics"
    },
    {
      "name": "cost_total",
      "display_name": "Total Cost",
      "type": "number",
      "description": "Total cost for processing this request (USD)"
    },
    {
      "name": "cost_itemized",
      "display_name": "Itemized Cost",
      "type": "array",
      "description": "Detailed breakdown of costs"
    },
    {
      "name": "reasoning",
      "display_name": "Reasoning",
      "type": "string",
      "description": "The detailed reasoning chain from the model"
    },
    {
      "name": "refusal",
      "display_name": "Refusal",
      "type": "string",
      "description": "Model refusal response (if any)"
    }
  ],
  "pricing": {
    "reference": "https://openrouter.ai/models",
    "items": [
      {
        "key": "input_cost_per_million",
        "label": "Input Tokens (per 1M)",
        "cost": 0,
        "currency": "USD"
      },
      {
        "key": "output_cost_per_million",
        "label": "Output Tokens (per 1M)",
        "cost": 0,
        "currency": "USD"
      }
    ]
  }
}